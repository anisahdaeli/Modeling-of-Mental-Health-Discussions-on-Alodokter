{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def get_links_from_page(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an error for bad status codes\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    topic_list = soup.find(id='topic-list')\n",
        "    if not topic_list:\n",
        "        return []\n",
        "\n",
        "    links = []\n",
        "    for card in topic_list.find_all('card-topic'):\n",
        "        href = card.get('href')\n",
        "        if href:\n",
        "            links.append('https://www.alodokter.com' + href)\n",
        "    return links\n",
        "\n",
        "def scrape_all_pages(base_url, start_page=1, delay=5):\n",
        "    all_links = []\n",
        "    page = start_page\n",
        "    while True:\n",
        "        try:\n",
        "            url = f\"{base_url}{page}\"\n",
        "            print(f\"Scraping page: {page}\")\n",
        "            links = get_links_from_page(url)\n",
        "            if not links:\n",
        "                print(f\"No more links found. Stopping at page {page-1}.\")\n",
        "                break\n",
        "            all_links.extend(links)\n",
        "            page += 1\n",
        "            time.sleep(delay)  # Add delay between requests\n",
        "        except requests.HTTPError as e:\n",
        "            if e.response.status_code == 404:\n",
        "                print(f\"Page {page} not found. Stopping.\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"HTTP error occurred: {e}\")\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "def save_links_to_csv(links, filename='terapi-perilaku-kognitif.csv'):\n",
        "    df = pd.DataFrame(links, columns=['Link'])\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Data saved to {filename}\")\n",
        "\n",
        "base_url = \"https://www.alodokter.com/komunitas/topic-tag/terapi-perilaku-kognitif/page/\"\n",
        "all_links = scrape_all_pages(base_url)\n",
        "save_links_to_csv(all_links)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGgDVT_gmgOn",
        "outputId": "1b262b2f-b42f-485d-8054-3a647416c7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Scraping page: 2\n",
            "Scraping page: 3\n",
            "No more links found. Stopping at page 2.\n",
            "Data saved to terapi-perilaku-kognitif.csv\n"
          ]
        }
      ]
    }
  ]
}