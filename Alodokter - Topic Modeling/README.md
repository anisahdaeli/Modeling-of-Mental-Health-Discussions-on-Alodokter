# Topic Modeling of Mental Health Discussions on Alodokter

<img width="1920" height="1284" alt="image" src="https://github.com/user-attachments/assets/d377a176-a509-44a8-9d65-d0c710dd33af" />

This folder focuses on analyzing mental health discussions from the **Alodokter** platform using **Natural Language Processing (NLP)** techniques. The project covers the complete data pipeline, starting from automated data collection (web scraping), Indonesian text preprocessing, to topic modeling using the **Latent Dirichlet Allocation (LDA)** algorithm.

---

## üìÅ Folder Structure

### 1. Scrapping Data
This folder contains documentation and scripts for primary data collection:

- **Stage 1 (Link Scraping):** Collecting discussion URLs from mental health-related categories.
- **Stage 2 (Content Scraping):** Extracting textual content from each collected URL.
- **Stage 3 (Data Integration):** Data validation, merging multiple extraction results, and basic cleaning to remove duplicates and empty records.

---

### 2. LDA - Modeling
This folder is the core of the topic modeling experiments, exploring various text representation techniques:

- **LDA_BOW.ipynb**  
  Topic modeling using the Bag of Words (BoW) approach.

- **LDA_TF_IDF.ipynb**  
  Topic modeling using Term Frequency‚ÄìInverse Document Frequency (TF-IDF) weighting.

- **LDA_BIGRAM_nltk.ipynb**  
  Topic modeling experiments using bigrams with the NLTK library.

- **LDA_BIGRAM_ClassPhrasesGengsim.ipynb**  
  Bigram implementation using the *Phrases* module from the Gensim library to capture more meaningful word phrases.

---

### 3. Result
This folder contains the final outputs of the data processing and modeling:

- **Data Recapitulation:** Files mapping each discussion document to its dominant topic generated by the model.
- **pyLDAvis Visualizations:** Interactive visual representations for analyzing topic distances and key terms that form each topic.

---

### 4. Snippet
This folder contains visual documentation in the form of screenshots showing program execution as evidence of successful runs and as interface references.

---

## üìÑ Main Files in Root Directory
The following files connect all stages of the topic modeling process:

- **alodokter topik.csv**  
  Raw dataset generated from the initial web scraping process.

- **LDA_Preprocessing_Data.ipynb**  
  A dedicated notebook for advanced text preprocessing, including normalization, filtering, Indonesian medical stopword removal, and stemming.

- **data fix.csv**  
  Final preprocessed dataset ready to be used as input for LDA modeling.

- **Visualisasi_Data_Topik.ipynb**  
  Main notebook for generating final visualizations and analyzing topic distributions.

---

## ‚öôÔ∏è Workflow Pipeline

1. **Extraction**  
   Run scripts in the *Scrapping Data* folder to generate `alodokter topik.csv`.

2. **Preprocessing**  
   Process `alodokter topik.csv` using `LDA_Preprocessing_Data.ipynb` to produce `data fix.csv`.

3. **Modeling Experiments**  
   Use `data fix.csv` as input for notebooks in the *LDA - Modeling* folder (BoW, TF-IDF, or Bigrams) to identify the model with the best coherence score.

4. **Final Analysis**  
   Visualize and analyze topic modeling results using `Visualisasi_Data_Topik.ipynb`, with outputs stored in the *Result* folder.
